{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "import optuna\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(\"data/train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 455163 entries, 48321 to 928462\n",
      "Data columns (total 11 columns):\n",
      " #   Column                     Non-Null Count   Dtype         \n",
      "---  ------                     --------------   -----         \n",
      " 0   counter_id                 455163 non-null  category      \n",
      " 1   counter_name               455163 non-null  category      \n",
      " 2   site_id                    455163 non-null  int64         \n",
      " 3   site_name                  455163 non-null  category      \n",
      " 4   bike_count                 455163 non-null  float64       \n",
      " 5   date                       455163 non-null  datetime64[ns]\n",
      " 6   counter_installation_date  455163 non-null  datetime64[ns]\n",
      " 7   counter_technical_id       455163 non-null  category      \n",
      " 8   latitude                   455163 non-null  float64       \n",
      " 9   longitude                  455163 non-null  float64       \n",
      " 10  log_bike_count             455163 non-null  float64       \n",
      "dtypes: category(4), datetime64[ns](2), float64(4), int64(1)\n",
      "memory usage: 29.5 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "data[\"day_of_week\"] = data[\"date\"].dt.dayofweek\n",
    "data[\"month\"] = data[\"date\"].dt.month\n",
    "data[\"hour\"] = data[\"date\"].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\n",
    "    \"counter_name\",\n",
    "    \"site_name\",\n",
    "    \"counter_technical_id\",\n",
    "    \"day_of_week\",\n",
    "    \"month\",\n",
    "    \"hour\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = [\"latitude\", \"longitude\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in categorical_cols:\n",
    "    data[feature] = data[feature].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop_train = [\"counter_id\", \"site_id\", \"date\", \"counter_installation_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(cols_to_drop_train, axis=1)\n",
    "data = data.drop(\"bike_count\", axis=1)\n",
    "X = data.drop(\"log_bike_count\", axis=1)\n",
    "y = data[\"log_bike_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(drop=\"first\", sparse_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded = pd.DataFrame(encoder.fit_transform(X[categorical_cols]))\n",
    "X = pd.concat([X.drop(categorical_cols, axis=1), X_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [724554, 455163]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Ecole-Polytechnique\\M1\\Python-for-Data-Science\\Project\\Bike-Counters-Ameya---Qiling\\XGBoost Adaboost.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Ecole-Polytechnique/M1/Python-for-Data-Science/Project/Bike-Counters-Ameya---Qiling/XGBoost%20Adaboost.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Ecole-Polytechnique/M1/Python-for-Data-Science/Project/Bike-Counters-Ameya---Qiling/XGBoost%20Adaboost.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     X, y, test_size\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Ecole-Polytechnique/M1/Python-for-Data-Science/Project/Bike-Counters-Ameya---Qiling/XGBoost%20Adaboost.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    215\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2646\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2643\u001b[0m \u001b[39mif\u001b[39;00m n_arrays \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   2644\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAt least one array required as input\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 2646\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39;49marrays)\n\u001b[0;32m   2648\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[0;32m   2649\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2650\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39m\u001b[39m0.25\u001b[39m\n\u001b[0;32m   2651\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\sklearn\\utils\\validation.py:453\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \n\u001b[0;32m    436\u001b[0m \u001b[39mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[39m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    452\u001b[0m result \u001b[39m=\u001b[39m [_make_indexable(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m iterables]\n\u001b[1;32m--> 453\u001b[0m check_consistent_length(\u001b[39m*\u001b[39;49mresult)\n\u001b[0;32m    454\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\sklearn\\utils\\validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    405\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    406\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 407\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    408\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    409\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    410\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [724554, 455163]"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"booster\": \"gbtree\",\n",
    "        \"eval_metric\": \"rmse\",\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.8, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.8, 1.0),\n",
    "    }\n",
    "\n",
    "    xgb_model = XGBRegressor(**params)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-06 14:29:54,884] A new study created in memory with name: no-name-3d0e20b7-3c93-40b9-941d-e14b8c246730\n",
      "[W 2023-12-06 14:29:54,896] Trial 0 failed with parameters: {'learning_rate': 0.10996874594655182, 'max_depth': 6, 'n_estimators': 102, 'subsample': 0.9554536686097066, 'colsample_bytree': 0.8719521793150562} because of the following error: ValueError('DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:counter_name: category, site_name: category, counter_technical_id: category, day_of_week: category, month: category, hour: category').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\ameya\\AppData\\Local\\Temp\\ipykernel_24348\\1989577182.py\", line 14, in objective\n",
      "    xgb_model.fit(X_train, y_train)\n",
      "  File \"c:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\xgboost\\sklearn.py\", line 988, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "  File \"c:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\xgboost\\sklearn.py\", line 448, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "  File \"c:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\xgboost\\sklearn.py\", line 908, in _create_dmatrix\n",
      "    return DMatrix(**kwargs, nthread=self.n_jobs)\n",
      "  File \"c:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\xgboost\\core.py\", line 743, in __init__\n",
      "    handle, feature_names, feature_types = dispatch_data_backend(\n",
      "  File \"c:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\xgboost\\data.py\", line 957, in dispatch_data_backend\n",
      "    return _from_pandas_df(data, enable_categorical, missing, threads,\n",
      "  File \"c:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\xgboost\\data.py\", line 404, in _from_pandas_df\n",
      "    data, feature_names, feature_types = _transform_pandas_df(\n",
      "  File \"c:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\xgboost\\data.py\", line 378, in _transform_pandas_df\n",
      "    _invalid_dataframe_dtype(data)\n",
      "  File \"c:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\xgboost\\data.py\", line 270, in _invalid_dataframe_dtype\n",
      "    raise ValueError(msg)\n",
      "ValueError: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:counter_name: category, site_name: category, counter_technical_id: category, day_of_week: category, month: category, hour: category\n",
      "[W 2023-12-06 14:29:54,900] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:counter_name: category, site_name: category, counter_technical_id: category, day_of_week: category, month: category, hour: category",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Ecole-Polytechnique\\M1\\Python-for-Data-Science\\Project\\Bike-Counters-Ameya---Qiling\\XGBoost Adaboost.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Ecole-Polytechnique/M1/Python-for-Data-Science/Project/Bike-Counters-Ameya---Qiling/XGBoost%20Adaboost.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Ecole-Polytechnique/M1/Python-for-Data-Science/Project/Bike-Counters-Ameya---Qiling/XGBoost%20Adaboost.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)  \u001b[39m# You can adjust the number of trials\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     _optimize(\n\u001b[0;32m    452\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    453\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    454\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    455\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    456\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    457\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[0;32m    458\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    459\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    460\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    461\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32md:\\Ecole-Polytechnique\\M1\\Python-for-Data-Science\\Project\\Bike-Counters-Ameya---Qiling\\XGBoost Adaboost.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Ecole-Polytechnique/M1/Python-for-Data-Science/Project/Bike-Counters-Ameya---Qiling/XGBoost%20Adaboost.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Ecole-Polytechnique/M1/Python-for-Data-Science/Project/Bike-Counters-Ameya---Qiling/XGBoost%20Adaboost.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mreg:squarederror\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Ecole-Polytechnique/M1/Python-for-Data-Science/Project/Bike-Counters-Ameya---Qiling/XGBoost%20Adaboost.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbooster\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mgbtree\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Ecole-Polytechnique/M1/Python-for-Data-Science/Project/Bike-Counters-Ameya---Qiling/XGBoost%20Adaboost.ipynb#X43sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolsample_bytree\u001b[39m\u001b[39m\"\u001b[39m: trial\u001b[39m.\u001b[39msuggest_float(\u001b[39m\"\u001b[39m\u001b[39mcolsample_bytree\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0.8\u001b[39m, \u001b[39m1.0\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Ecole-Polytechnique/M1/Python-for-Data-Science/Project/Bike-Counters-Ameya---Qiling/XGBoost%20Adaboost.ipynb#X43sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m }\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Ecole-Polytechnique/M1/Python-for-Data-Science/Project/Bike-Counters-Ameya---Qiling/XGBoost%20Adaboost.ipynb#X43sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m xgb_model \u001b[39m=\u001b[39m XGBRegressor(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Ecole-Polytechnique/M1/Python-for-Data-Science/Project/Bike-Counters-Ameya---Qiling/XGBoost%20Adaboost.ipynb#X43sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m xgb_model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Ecole-Polytechnique/M1/Python-for-Data-Science/Project/Bike-Counters-Ameya---Qiling/XGBoost%20Adaboost.ipynb#X43sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m y_pred \u001b[39m=\u001b[39m xgb_model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Ecole-Polytechnique/M1/Python-for-Data-Science/Project/Bike-Counters-Ameya---Qiling/XGBoost%20Adaboost.ipynb#X43sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m mse \u001b[39m=\u001b[39m mean_squared_error(y_test, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\xgboost\\sklearn.py:988\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m    986\u001b[0m \u001b[39mwith\u001b[39;00m config_context(verbosity\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbosity):\n\u001b[0;32m    987\u001b[0m     evals_result: TrainingCallback\u001b[39m.\u001b[39mEvalsLog \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 988\u001b[0m     train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m    989\u001b[0m         missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[0;32m    990\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    991\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    992\u001b[0m         group\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    993\u001b[0m         qid\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    994\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    995\u001b[0m         base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[0;32m    996\u001b[0m         feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[0;32m    997\u001b[0m         eval_set\u001b[39m=\u001b[39;49meval_set,\n\u001b[0;32m    998\u001b[0m         sample_weight_eval_set\u001b[39m=\u001b[39;49msample_weight_eval_set,\n\u001b[0;32m    999\u001b[0m         base_margin_eval_set\u001b[39m=\u001b[39;49mbase_margin_eval_set,\n\u001b[0;32m   1000\u001b[0m         eval_group\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1001\u001b[0m         eval_qid\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1002\u001b[0m         create_dmatrix\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_dmatrix,\n\u001b[0;32m   1003\u001b[0m         enable_categorical\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menable_categorical,\n\u001b[0;32m   1004\u001b[0m         feature_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_types,\n\u001b[0;32m   1005\u001b[0m     )\n\u001b[0;32m   1006\u001b[0m     params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1008\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n",
      "File \u001b[1;32mc:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\xgboost\\sklearn.py:448\u001b[0m, in \u001b[0;36m_wrap_evaluation_matrices\u001b[1;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrap_evaluation_matrices\u001b[39m(\n\u001b[0;32m    429\u001b[0m     missing: \u001b[39mfloat\u001b[39m,\n\u001b[0;32m    430\u001b[0m     X: Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    444\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[0;32m    445\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Any, List[Tuple[Any, \u001b[39mstr\u001b[39m]]]:\n\u001b[0;32m    446\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[39m    way.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 448\u001b[0m     train_dmatrix \u001b[39m=\u001b[39m create_dmatrix(\n\u001b[0;32m    449\u001b[0m         data\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    450\u001b[0m         label\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    451\u001b[0m         group\u001b[39m=\u001b[39;49mgroup,\n\u001b[0;32m    452\u001b[0m         qid\u001b[39m=\u001b[39;49mqid,\n\u001b[0;32m    453\u001b[0m         weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    454\u001b[0m         base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[0;32m    455\u001b[0m         feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[0;32m    456\u001b[0m         missing\u001b[39m=\u001b[39;49mmissing,\n\u001b[0;32m    457\u001b[0m         enable_categorical\u001b[39m=\u001b[39;49menable_categorical,\n\u001b[0;32m    458\u001b[0m         feature_types\u001b[39m=\u001b[39;49mfeature_types,\n\u001b[0;32m    459\u001b[0m         ref\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    460\u001b[0m     )\n\u001b[0;32m    462\u001b[0m     n_validation \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m eval_set \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mlen\u001b[39m(eval_set)\n\u001b[0;32m    464\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mvalidate_or_none\u001b[39m(meta: Optional[Sequence], name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Sequence:\n",
      "File \u001b[1;32mc:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\xgboost\\sklearn.py:908\u001b[0m, in \u001b[0;36mXGBModel._create_dmatrix\u001b[1;34m(self, ref, **kwargs)\u001b[0m\n\u001b[0;32m    906\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:  \u001b[39m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[0;32m    907\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m--> 908\u001b[0m \u001b[39mreturn\u001b[39;00m DMatrix(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs, nthread\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mc:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\xgboost\\core.py:743\u001b[0m, in \u001b[0;36mDMatrix.__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical)\u001b[0m\n\u001b[0;32m    740\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    741\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 743\u001b[0m handle, feature_names, feature_types \u001b[39m=\u001b[39m dispatch_data_backend(\n\u001b[0;32m    744\u001b[0m     data,\n\u001b[0;32m    745\u001b[0m     missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[0;32m    746\u001b[0m     threads\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnthread,\n\u001b[0;32m    747\u001b[0m     feature_names\u001b[39m=\u001b[39;49mfeature_names,\n\u001b[0;32m    748\u001b[0m     feature_types\u001b[39m=\u001b[39;49mfeature_types,\n\u001b[0;32m    749\u001b[0m     enable_categorical\u001b[39m=\u001b[39;49menable_categorical,\n\u001b[0;32m    750\u001b[0m )\n\u001b[0;32m    751\u001b[0m \u001b[39massert\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    752\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle \u001b[39m=\u001b[39m handle\n",
      "File \u001b[1;32mc:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\xgboost\\data.py:957\u001b[0m, in \u001b[0;36mdispatch_data_backend\u001b[1;34m(data, missing, threads, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[0;32m    955\u001b[0m     \u001b[39mreturn\u001b[39;00m _from_tuple(data, missing, threads, feature_names, feature_types)\n\u001b[0;32m    956\u001b[0m \u001b[39mif\u001b[39;00m _is_pandas_df(data):\n\u001b[1;32m--> 957\u001b[0m     \u001b[39mreturn\u001b[39;00m _from_pandas_df(data, enable_categorical, missing, threads,\n\u001b[0;32m    958\u001b[0m                            feature_names, feature_types)\n\u001b[0;32m    959\u001b[0m \u001b[39mif\u001b[39;00m _is_pandas_series(data):\n\u001b[0;32m    960\u001b[0m     \u001b[39mreturn\u001b[39;00m _from_pandas_series(\n\u001b[0;32m    961\u001b[0m         data, missing, threads, enable_categorical, feature_names, feature_types\n\u001b[0;32m    962\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\xgboost\\data.py:404\u001b[0m, in \u001b[0;36m_from_pandas_df\u001b[1;34m(data, enable_categorical, missing, nthread, feature_names, feature_types)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_from_pandas_df\u001b[39m(\n\u001b[0;32m    397\u001b[0m     data: DataFrame,\n\u001b[0;32m    398\u001b[0m     enable_categorical: \u001b[39mbool\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    402\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[0;32m    403\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DispatchedDataBackendReturnType:\n\u001b[1;32m--> 404\u001b[0m     data, feature_names, feature_types \u001b[39m=\u001b[39m _transform_pandas_df(\n\u001b[0;32m    405\u001b[0m         data, enable_categorical, feature_names, feature_types\n\u001b[0;32m    406\u001b[0m     )\n\u001b[0;32m    407\u001b[0m     \u001b[39mreturn\u001b[39;00m _from_numpy_array(data, missing, nthread, feature_names, feature_types)\n",
      "File \u001b[1;32mc:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\xgboost\\data.py:378\u001b[0m, in \u001b[0;36m_transform_pandas_df\u001b[1;34m(data, enable_categorical, feature_names, feature_types, meta, meta_type)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m    367\u001b[0m     is_sparse,\n\u001b[0;32m    368\u001b[0m     is_categorical_dtype,\n\u001b[0;32m    369\u001b[0m )\n\u001b[0;32m    371\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[0;32m    372\u001b[0m     dtype\u001b[39m.\u001b[39mname \u001b[39min\u001b[39;00m _pandas_dtype_mapper\n\u001b[0;32m    373\u001b[0m     \u001b[39mor\u001b[39;00m is_sparse(dtype)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m     \u001b[39mfor\u001b[39;00m dtype \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mdtypes\n\u001b[0;32m    377\u001b[0m ):\n\u001b[1;32m--> 378\u001b[0m     _invalid_dataframe_dtype(data)\n\u001b[0;32m    380\u001b[0m feature_names, feature_types \u001b[39m=\u001b[39m _pandas_feature_info(\n\u001b[0;32m    381\u001b[0m     data, meta, feature_names, feature_types, enable_categorical\n\u001b[0;32m    382\u001b[0m )\n\u001b[0;32m    384\u001b[0m transformed \u001b[39m=\u001b[39m _pandas_cat_null(data)\n",
      "File \u001b[1;32mc:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\xgboost\\data.py:270\u001b[0m, in \u001b[0;36m_invalid_dataframe_dtype\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    268\u001b[0m type_err \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDataFrame.dtypes for data must be int, float, bool or category.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    269\u001b[0m msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\u001b[39m{\u001b[39;00mtype_err\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m_ENABLE_CAT_ERR\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00merr\u001b[39m}\u001b[39;00m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m--> 270\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:counter_name: category, site_name: category, counter_technical_id: category, day_of_week: category, month: category, hour: category"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50)  # You can adjust the number of trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = XGBRegressor(enable_categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Experimental support for categorical data is not implemented for current tree method yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Ecole-Polytechnique\\M1\\Python-for-Data-Science\\Project\\Bike-Counters-Ameya---Qiling\\XGBoost Adaboost.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Ecole-Polytechnique/M1/Python-for-Data-Science/Project/Bike-Counters-Ameya---Qiling/XGBoost%20Adaboost.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m reg\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[1;32mc:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\xgboost\\sklearn.py:1022\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1013\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1014\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m (\n\u001b[0;32m   1017\u001b[0m     model,\n\u001b[0;32m   1018\u001b[0m     metric,\n\u001b[0;32m   1019\u001b[0m     params,\n\u001b[0;32m   1020\u001b[0m     early_stopping_rounds,\n\u001b[0;32m   1021\u001b[0m     callbacks,\n\u001b[1;32m-> 1022\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_configure_fit(\n\u001b[0;32m   1023\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1024\u001b[0m )\n\u001b[0;32m   1025\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m   1026\u001b[0m     params,\n\u001b[0;32m   1027\u001b[0m     train_dmatrix,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1036\u001b[0m     callbacks\u001b[39m=\u001b[39mcallbacks,\n\u001b[0;32m   1037\u001b[0m )\n\u001b[0;32m   1039\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_evaluation_result(evals_result)\n",
      "File \u001b[1;32mc:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\xgboost\\sklearn.py:892\u001b[0m, in \u001b[0;36mXGBModel._configure_fit\u001b[1;34m(self, booster, eval_metric, params, early_stopping_rounds, callbacks)\u001b[0m\n\u001b[0;32m    890\u001b[0m cat_support \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mgpu_hist\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mapprox\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhist\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m    891\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menable_categorical \u001b[39mand\u001b[39;00m tree_method \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m cat_support:\n\u001b[1;32m--> 892\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    893\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExperimental support for categorical data is not implemented for\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    894\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m current tree method yet.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    895\u001b[0m     )\n\u001b[0;32m    897\u001b[0m \u001b[39mreturn\u001b[39;00m model, metric, params, early_stopping_rounds, callbacks\n",
      "\u001b[1;31mValueError\u001b[0m: Experimental support for categorical data is not implemented for current tree method yet."
     ]
    }
   ],
   "source": [
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_predictions = best_cat_reg.predict(X_train)\n",
    "catboost_predictions_2d = np.expand_dims(catboost_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost = AdaBoostRegressor(\n",
    "    base_estimator=best_cat_reg,\n",
    "    n_estimators=10,\n",
    "    random_state=42,\n",
    "    learning_rate=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BaseWeightBoosting.fit() got an unexpected keyword argument 'feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Ecole-Polytechnique\\M1\\Python-for-Data-Science\\Project\\Bike-Counters-Ameya---Qiling\\submission_cat_nb.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Ecole-Polytechnique/M1/Python-for-Data-Science/Project/Bike-Counters-Ameya---Qiling/submission_cat_nb.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ada_boost\u001b[39m.\u001b[39;49mfit(X_train, y_train, feature_names\u001b[39m=\u001b[39;49mfeature_names)\n",
      "File \u001b[1;32mc:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: BaseWeightBoosting.fit() got an unexpected keyword argument 'feature_names'"
     ]
    }
   ],
   "source": [
    "ada_boost.fit(X_train, y_train, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_parquet(\"data/final_test.parquet\")\n",
    "test_data[\"date\"] = pd.to_datetime(test_data[\"date\"])\n",
    "test_data[\"day_of_week\"] = test_data[\"date\"].dt.dayofweek\n",
    "test_data[\"month\"] = test_data[\"date\"].dt.month\n",
    "test_data[\"hour\"] = test_data[\"date\"].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop_test = [\n",
    "    \"counter_id\",\n",
    "    \"site_id\",\n",
    "    \"date\",\n",
    "    \"counter_installation_date\",\n",
    "    \"coordinates\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop(cols_to_drop_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_cat = best_cat_reg.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_cat_2d = np.expand_dims(predictions_cat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost_predictions = ada_boost.predict(predictions_cat_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame({\"log_bike_count\": ada_boost_predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.to_csv(\"submissions.csv\", index=True, index_label=\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = pd.read_parquet(\"data/train_kaggle.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 496827 entries, 48321 to 929187\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count   Dtype         \n",
      "---  ------                     --------------   -----         \n",
      " 0   counter_id                 496827 non-null  category      \n",
      " 1   counter_name               496827 non-null  category      \n",
      " 2   site_id                    496827 non-null  int64         \n",
      " 3   site_name                  496827 non-null  category      \n",
      " 4   bike_count                 496827 non-null  float64       \n",
      " 5   date                       496827 non-null  datetime64[ns]\n",
      " 6   counter_installation_date  496827 non-null  datetime64[ns]\n",
      " 7   coordinates                496827 non-null  category      \n",
      " 8   counter_technical_id       496827 non-null  category      \n",
      " 9   latitude                   496827 non-null  float64       \n",
      " 10  longitude                  496827 non-null  float64       \n",
      " 11  log_bike_count             496827 non-null  float64       \n",
      "dtypes: category(5), datetime64[ns](2), float64(4), int64(1)\n",
      "memory usage: 32.7 MB\n"
     ]
    }
   ],
   "source": [
    "bs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bikes-count",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

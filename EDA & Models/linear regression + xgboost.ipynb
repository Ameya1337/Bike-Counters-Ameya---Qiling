{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.tseries.holiday import Holiday, AbstractHolidayCalendar\n",
    "from dateutil.easter import easter\n",
    "from datetime import timedelta\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(Path(\"data\") / \"train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_parquet(Path(\"data\") / \"final_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrenchHolidayCalendar(AbstractHolidayCalendar):\n",
    "    rules = [\n",
    "        Holiday(\"New Year's Day\", month=1, day=1),\n",
    "        Holiday(\"Labour Day\", month=5, day=1),\n",
    "        Holiday(\"Victory in Europe Day\", month=5, day=8),\n",
    "        Holiday(\"Bastille Day\", month=7, day=14),\n",
    "        Holiday(\"Assumption of Mary\", month=8, day=15),\n",
    "        Holiday(\"All Saints' Day\", month=11, day=1),\n",
    "        Holiday(\"Armistice Day\", month=11, day=11),\n",
    "        Holiday(\"Christmas Day\", month=12, day=25),\n",
    "    ]\n",
    "\n",
    "    @staticmethod\n",
    "    def easter_related_holidays(year):\n",
    "        easter_sunday = easter(year)\n",
    "        return [\n",
    "            (easter_sunday + timedelta(days=1), \"Easter Monday\"),\n",
    "            (easter_sunday + timedelta(days=39), \"Ascension Day\"),\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _encode_dates(X):\n",
    "    X = X.copy()  # modify a copy of X\n",
    "    X[\"date\"] = X.index\n",
    "\n",
    "    # Encode the date information\n",
    "    X.loc[:, \"year\"] = X[\"date\"].dt.year\n",
    "    X.loc[:, \"month\"] = X[\"date\"].dt.month\n",
    "    X.loc[:, \"day\"] = X[\"date\"].dt.day\n",
    "    X.loc[:, \"weekday\"] = X[\"date\"].dt.weekday\n",
    "    X.loc[:, \"hour\"] = X[\"date\"].dt.hour\n",
    "\n",
    "    # Boolean feature for weekends\n",
    "    X.loc[:, \"is_weekend\"] = X[\"weekday\"].isin(\n",
    "        [5, 6]\n",
    "    )  # 5 and 6 correspond to Saturday and Sunday\n",
    "\n",
    "    # Boolean feature for holidays\n",
    "    cal = FrenchHolidayCalendar()\n",
    "    holidays = cal.holidays(start=X[\"date\"].min(), end=X[\"date\"].max())\n",
    "\n",
    "    # Add Easter related holidays\n",
    "    easter_holidays = []\n",
    "    for year in range(X[\"date\"].dt.year.min(), X[\"date\"].dt.year.max() + 1):\n",
    "        for date, _ in FrenchHolidayCalendar.easter_related_holidays(year):\n",
    "            easter_holidays.append(date)\n",
    "\n",
    "    holidays = holidays.union(pd.to_datetime(easter_holidays))\n",
    "    X.loc[:, \"is_holiday\"] = X[\"date\"].isin(holidays)\n",
    "\n",
    "    return X.drop(columns=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cyclical_encode(df, column, max_value):\n",
    "    df[column + \"_sin\"] = np.sin(2 * np.pi * df[column] / max_value)\n",
    "    df[column + \"_cos\"] = np.cos(2 * np.pi * df[column] / max_value)\n",
    "    return df\n",
    "\n",
    "\n",
    "def encode_cyclical_features(X):\n",
    "    X = X.copy()\n",
    "\n",
    "    X = cyclical_encode(X, \"hour\", 24)\n",
    "\n",
    "    X = cyclical_encode(X, \"weekday\", 7)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_lockdown_periods(X):\n",
    "    X = X.copy()\n",
    "    X[\"date\"] = X.index\n",
    "\n",
    "    # Define lockdown periods\n",
    "    lockdowns = {\n",
    "        \"lockdown_1\": (\"2020-03-17\", \"2020-05-10\"),\n",
    "        \"lockdown_2\": (\"2020-10-28\", \"2020-12-01\"),\n",
    "        # with curfew from 7 PM to 6 AM\n",
    "        \"lockdown_3_1\": (\"2021-04-03\", \"2021-05-18\"),\n",
    "        # with curfew from 9 PM to 6 AM\n",
    "        \"lockdown_3_2\": (\"2021-05-19\", \"2021-06-08\"),\n",
    "        # with curfew from 11 PM to 6 AM\n",
    "        \"lockdown_3_3\": (\"2021-06-09\", \"2021-06-29\"),\n",
    "    }\n",
    "\n",
    "    # Initialize lockdown columns to False\n",
    "    for lockdown in lockdowns:\n",
    "        X[lockdown] = False\n",
    "\n",
    "    # Mark the lockdown periods\n",
    "    for lockdown, (start_date, end_date) in lockdowns.items():\n",
    "        mask = (X[\"date\"] >= start_date) & (X[\"date\"] <= end_date)\n",
    "        X.loc[mask, lockdown] = True\n",
    "\n",
    "    return X.drop(columns=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = pd.read_csv(\"data/external_data_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'week' and 'day' columns\n",
    "weather_data = weather_data.drop(columns=[\"week\", \"day\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "weather_data[\"date\"] = pd.to_datetime(weather_data[\"date\"])\n",
    "test_data[\"date\"] = pd.to_datetime(test_data[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index(\"date\", inplace=True)\n",
    "weather_data.set_index(\"date\", inplace=True)\n",
    "test_data.set_index(\"date\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 3321 entries, 2021-01-01 00:00:00 to 2020-09-30 21:00:00\n",
      "Data columns (total 15 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   t              3321 non-null   float64\n",
      " 1   rr1            3321 non-null   float64\n",
      " 2   rr3            3321 non-null   float64\n",
      " 3   rr6            3321 non-null   float64\n",
      " 4   ff             3321 non-null   float64\n",
      " 5   raf10          3321 non-null   float64\n",
      " 6   rafper         3321 non-null   float64\n",
      " 7   u              3321 non-null   int64  \n",
      " 8   vv             3321 non-null   int64  \n",
      " 9   n              3321 non-null   float64\n",
      " 10  cl             3321 non-null   float64\n",
      " 11  cm             3321 non-null   float64\n",
      " 12  ch             3321 non-null   float64\n",
      " 13  precipitation  3321 non-null   int64  \n",
      " 14  cloudy_day     3321 non-null   int64  \n",
      "dtypes: float64(11), int64(4)\n",
      "memory usage: 415.1 KB\n"
     ]
    }
   ],
   "source": [
    "weather_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_hourly = weather_data.resample(\"H\").ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = data.merge(\n",
    "    weather_data_hourly, left_on=\"date\", right_index=True, how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_test_data = test_data.merge(\n",
    "    weather_data_hourly, left_on=\"date\", right_index=True, how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 51440 entries, 2021-09-10 01:00:00 to 2021-09-27 11:00:00\n",
      "Data columns (total 24 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   counter_id                 51440 non-null  category      \n",
      " 1   counter_name               51440 non-null  category      \n",
      " 2   site_id                    51440 non-null  int64         \n",
      " 3   site_name                  51440 non-null  category      \n",
      " 4   counter_installation_date  51440 non-null  datetime64[ns]\n",
      " 5   coordinates                51440 non-null  category      \n",
      " 6   counter_technical_id       51440 non-null  category      \n",
      " 7   latitude                   51440 non-null  float64       \n",
      " 8   longitude                  51440 non-null  float64       \n",
      " 9   t                          51440 non-null  float64       \n",
      " 10  rr1                        51440 non-null  float64       \n",
      " 11  rr3                        51440 non-null  float64       \n",
      " 12  rr6                        51440 non-null  float64       \n",
      " 13  ff                         51440 non-null  float64       \n",
      " 14  raf10                      51440 non-null  float64       \n",
      " 15  rafper                     51440 non-null  float64       \n",
      " 16  u                          51440 non-null  int64         \n",
      " 17  vv                         51440 non-null  int64         \n",
      " 18  n                          51440 non-null  float64       \n",
      " 19  cl                         51440 non-null  float64       \n",
      " 20  cm                         51440 non-null  float64       \n",
      " 21  ch                         51440 non-null  float64       \n",
      " 22  precipitation              51440 non-null  int64         \n",
      " 23  cloudy_day                 51440 non-null  int64         \n",
      "dtypes: category(5), datetime64[ns](1), float64(13), int64(5)\n",
      "memory usage: 8.1 MB\n"
     ]
    }
   ],
   "source": [
    "combined_test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = _encode_dates(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_test_data = _encode_dates(combined_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = encode_cyclical_features(combined_data)\n",
    "combined_test_data = encode_cyclical_features(combined_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = encode_lockdown_periods(combined_data)\n",
    "combined_test_data = encode_lockdown_periods(combined_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.drop(columns=[\"bike_count\", \"counter_id\", \"site_id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 'counter_age' column\n",
    "combined_data[\"counter_installation_date\"] = pd.to_datetime(\n",
    "    combined_data[\"counter_installation_date\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data[\"counter_age\"] = (\n",
    "    combined_data.index - combined_data[\"counter_installation_date\"]\n",
    ").dt.days\n",
    "combined_data.drop(columns=[\"counter_installation_date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lag and rolling features\n",
    "for lag in [1, 2, 7]:  # lags of 1 day, 2 days, and 1 week\n",
    "    combined_data[f\"log_bike_count_lag_{lag}\"] = combined_data[\"log_bike_count\"].shift(\n",
    "        lag\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lag in [1, 2, 7]:\n",
    "    combined_data[f\"log_bike_count_lag_{lag}_squared\"] = (\n",
    "        combined_data[f\"log_bike_count_lag_{lag}\"] ** 2\n",
    "    )\n",
    "    combined_data[f\"log_bike_count_lag_{lag}_cubed\"] = (\n",
    "        combined_data[f\"log_bike_count_lag_{lag}\"] ** 3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7-day rolling average\n",
    "combined_data[\"log_bike_count_rolling_7\"] = (\n",
    "    combined_data[\"log_bike_count\"].rolling(window=7).mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping NaN values created by lag and rolling features\n",
    "combined_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping or keeping latitude and longitude\n",
    "# combined_data.drop(columns=[\"latitude\", \"longitude\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_columns = [\n",
    "    \"is_weekend\",\n",
    "    \"is_holiday\",\n",
    "    \"lockdown_1\",\n",
    "    \"lockdown_2\",\n",
    "    \"lockdown_3_1\",\n",
    "    \"lockdown_3_2\",\n",
    "    \"lockdown_3_3\",\n",
    "]\n",
    "combined_data[bool_columns] = combined_data[bool_columns].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot-encoding\n",
    "categorical_columns = [\"counter_name\", \"site_name\", \"counter_technical_id\"]\n",
    "\n",
    "combined_data_encoded = pd.get_dummies(\n",
    "    combined_data, columns=categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data\n",
    "\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(combined_data_encoded) * split_ratio)\n",
    "\n",
    "X = combined_data_encoded.drop(columns=[\"log_bike_count\"])\n",
    "y = combined_data_encoded[\"log_bike_count\"]\n",
    "\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression for capturing trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_trend_train = lr_model.predict(X_train)\n",
    "lr_trend_test = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost on residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_train = y_train - lr_trend_train\n",
    "residuals_test = y_test - lr_trend_test\n",
    "\n",
    "xgb_model = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(X_train, residuals_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_residuals_train = xgb_model.predict(X_train)\n",
    "xgb_residuals_test = xgb_model.predict(X_test)\n",
    "\n",
    "# Combine predictions:\n",
    "final_predictions_train = lr_trend_train + xgb_residuals_train\n",
    "final_predictions_test = lr_trend_test + xgb_residuals_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.47213568069551176, MAE: 0.30230427810097044\n"
     ]
    }
   ],
   "source": [
    "rmse = mean_squared_error(y_test, final_predictions_test, squared=False)\n",
    "mae = mean_absolute_error(y_test, final_predictions_test)\n",
    "print(f\"RMSE: {rmse}, MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost in general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6741174340531096\n"
     ]
    }
   ],
   "source": [
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# processing test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_test_data.drop(columns=[\"counter_id\", \"site_id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 'counter_age' column\n",
    "combined_test_data[\"counter_installation_date\"] = pd.to_datetime(\n",
    "    combined_test_data[\"counter_installation_date\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_test_data[\"counter_age\"] = (\n",
    "    combined_test_data.index - combined_test_data[\"counter_installation_date\"]\n",
    ").dt.days\n",
    "combined_test_data.drop(columns=[\"counter_installation_date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating lag and rolling features\n",
    "for lag in [1, 2, 7]:  # lags of 1 day, 2 days, and 1 week\n",
    "    combined_test_data[f\"log_bike_count_lag_{lag}\"] = combined_test_data[\n",
    "        \"log_bike_count\"\n",
    "    ].shift(lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for lag in [1, 2, 7]:  # Assuming you have these lags\n",
    "    combined_test_data[f\"log_bike_count_lag_{lag}_squared\"] = (\n",
    "        combined_test_data[f\"log_bike_count_lag_{lag}\"] ** 2\n",
    "    )\n",
    "    combined_test_data[f\"log_bike_count_lag_{lag}_cubed\"] = (\n",
    "        combined_test_data[f\"log_bike_count_lag_{lag}\"] ** 3\n",
    "    )\n",
    "    # combined_test_data[f\"log_bike_count_lag_{lag}_order_4\"] = (\n",
    "    #    combined_test_data[f\"log_bike_count_lag_{lag}\"] ** 4\n",
    "    # )\n",
    "    # combined_test_data[f\"log_bike_count_lag_{lag}_order_5\"] = (\n",
    "    #    combined_test_data[f\"log_bike_count_lag_{lag}\"] ** 5\n",
    "    # )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7-day rolling average\n",
    "combined_test_data[\"log_bike_count_rolling_7\"] = (\n",
    "    combined_test_data[\"log_bike_count\"].rolling(window=7).mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping NaN values created by lag and rolling features\n",
    "combined_test_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping or keeping latitude and longitude\n",
    "# combined_test_data.drop(columns=[\"latitude\", \"longitude\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_columns = [\n",
    "    \"is_weekend\",\n",
    "    \"is_holiday\",\n",
    "    \"lockdown_1\",\n",
    "    \"lockdown_2\",\n",
    "    \"lockdown_3_1\",\n",
    "    \"lockdown_3_2\",\n",
    "    \"lockdown_3_3\",\n",
    "]\n",
    "combined_test_data[bool_columns] = combined_test_data[bool_columns].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot-encoding\n",
    "categorical_columns = [\"counter_name\", \"site_name\", \"counter_technical_id\"]\n",
    "\n",
    "combined_test_data_encoded = pd.get_dummies(\n",
    "    combined_test_data, columns=categorical_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 51440 entries, 2021-09-10 01:00:00 to 2021-09-27 11:00:00\n",
      "Columns: 151 entries, coordinates to counter_technical_id_YTH19111510\n",
      "dtypes: category(1), float64(17), int32(7), int64(10), uint8(116)\n",
      "memory usage: 18.1 MB\n"
     ]
    }
   ],
   "source": [
    "combined_test_data_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data = combined_test_data_encoded.drop(columns=[\"log_bike_count\"])\n",
    "y_test_data = combined_test_data_encoded[\"log_bike_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_trend_test_data = lr_model.predict(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_test_data = y_test_data - lr_trend_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_residuals_test_data = xgb_model.predict(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions_test_data = lr_trend_test_data + xgb_residuals_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_test = mean_squared_error(\n",
    "    y_test_data, final_predictions_test_data, squared=False)\n",
    "mae_test = mean_absolute_error(y_test_data, final_predictions_test_data)\n",
    "print(f\"RMSE: {rmse_test}, MAE: {mae_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = xgb_model.predict(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9156888716305859\n"
     ]
    }
   ],
   "source": [
    "rmse_test = mean_squared_error(y_test_data, y_test_pred, squared=False)\n",
    "print(f\"RMSE: {rmse_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If test data is unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_data = combined_test_data_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_data = unseen_data.drop(\"coordinates\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = unseen_data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_predictions = []  # to keep track of the last 7 predictions for rolling average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 150 features, but LinearRegression is expecting 160 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Ecole-Polytechnique\\M1\\Python-for-Data-Science\\Project\\Bike-Counters-Ameya---Qiling\\timeseries x machine learning.ipynb Cell 70\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Ecole-Polytechnique/M1/Python-for-Data-Science/Project/Bike-Counters-Ameya---Qiling/timeseries%20x%20machine%20learning.ipynb#Y232sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m current_features \u001b[39m=\u001b[39m unseen_data\u001b[39m.\u001b[39miloc[i]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Ecole-Polytechnique/M1/Python-for-Data-Science/Project/Bike-Counters-Ameya---Qiling/timeseries%20x%20machine%20learning.ipynb#Y232sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Predict the trend using the linear regression model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Ecole-Polytechnique/M1/Python-for-Data-Science/Project/Bike-Counters-Ameya---Qiling/timeseries%20x%20machine%20learning.ipynb#Y232sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m trend_prediction \u001b[39m=\u001b[39m lr_model\u001b[39m.\u001b[39;49mpredict(current_features)[\u001b[39m0\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Ecole-Polytechnique/M1/Python-for-Data-Science/Project/Bike-Counters-Ameya---Qiling/timeseries%20x%20machine%20learning.ipynb#Y232sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Predict the residual using the XGBoost model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Ecole-Polytechnique/M1/Python-for-Data-Science/Project/Bike-Counters-Ameya---Qiling/timeseries%20x%20machine%20learning.ipynb#Y232sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m residual_prediction \u001b[39m=\u001b[39m xgb_model\u001b[39m.\u001b[39mpredict(current_features)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\sklearn\\linear_model\\_base.py:386\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    373\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[39m    Predict using the linear model.\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[39m        Returns predicted values.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 386\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decision_function(X)\n",
      "File \u001b[1;32mc:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\sklearn\\linear_model\\_base.py:369\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_decision_function\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    367\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 369\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcoo\u001b[39;49m\u001b[39m\"\u001b[39;49m], reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    370\u001b[0m     \u001b[39mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n",
      "File \u001b[1;32mc:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\sklearn\\base.py:626\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    623\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 626\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    628\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\ameya\\miniforge-pypy3\\envs\\bikes-count\\lib\\site-packages\\sklearn\\base.py:415\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    412\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    414\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 415\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    416\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    418\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 150 features, but LinearRegression is expecting 160 features as input."
     ]
    }
   ],
   "source": [
    "for i in range(len(unseen_data)):\n",
    "    # Prepare the features for prediction\n",
    "    current_features = unseen_data.iloc[i].values.reshape(1, -1)\n",
    "\n",
    "    # Predict the trend using the linear regression model\n",
    "    trend_prediction = lr_model.predict(current_features)[0]\n",
    "\n",
    "    # Predict the residual using the XGBoost model\n",
    "    residual_prediction = xgb_model.predict(current_features)[0]\n",
    "\n",
    "    # Final prediction is the sum of trend and residual\n",
    "    final_prediction = trend_prediction + residual_prediction\n",
    "    rolling_predictions.append(final_prediction)\n",
    "\n",
    "    # Update lagged features for the next prediction\n",
    "    if i + 1 < len(unseen_data):\n",
    "        unseen_data.at[i + 1, \"log_bike_count_lag_1\"] = final_prediction\n",
    "        if i + 2 < len(unseen_data):\n",
    "            unseen_data.at[i + 2, \"log_bike_count_lag_2\"] = final_prediction\n",
    "        if i + 7 < len(unseen_data):\n",
    "            unseen_data.at[i + 7, \"log_bike_count_lag_7\"] = final_prediction\n",
    "\n",
    "    # Update squared and cubed lag features\n",
    "    for lag in [1, 2, 7]:\n",
    "        if i + lag < len(unseen_data):\n",
    "            unseen_data.at[i + lag, f\"log_bike_count_lag_{lag}_squared\"] = (\n",
    "                final_prediction**2\n",
    "            )\n",
    "            unseen_data.at[i + lag, f\"log_bike_count_lag_{lag}_cubed\"] = (\n",
    "                final_prediction**3\n",
    "            )\n",
    "\n",
    "    # Update rolling average\n",
    "    if len(rolling_predictions) > 7:\n",
    "        rolling_predictions.pop(0)  # keep only the last 7 predictions\n",
    "    if i + 1 < len(unseen_data):\n",
    "        unseen_data.at[i + 1, \"log_bike_count_rolling_7\"] = np.mean(rolling_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bikes-count",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
